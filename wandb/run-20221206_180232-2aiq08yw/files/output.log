Done.
Setting up the random seed for reproducibility...
Done.
Initializing model...
Done.
Initializing datasets...
Done.
Initializing clients...
Done.
Initializing server...
Running without server optimizer
Done.
Initialize return score, metrics, ckpt, ckpt step...
Setting up metrics...
Done.
Done.
Initializing optimizer and scheduler...
Done.
Generating sample ids for plots...
Done.
The experiment begins...
ROUND 1/500: Training 10 Clients...
CLIENT 1/10: erfurt5
Traceback (most recent call last):
  File "/home/utente/Scrivania/PROVA/LADD/src/run.py", line 47, in <module>
    run_experiment()
  File "/home/utente/Scrivania/PROVA/LADD/src/run.py", line 18, in run_experiment
    max_score = trainer.train(*trainer.train_args, **trainer.train_kwargs)
  File "/home/utente/Scrivania/PROVA/LADD/src/federated/trainers/oracle_trainer.py", line 53, in train
    return self.perform_fed_oracle_training(
  File "/home/utente/Scrivania/PROVA/LADD/src/federated/trainers/oracle_trainer.py", line 34, in perform_fed_oracle_training
    losses = self.server.train_clients(partial_metric=partial_train_metric)
  File "/home/utente/Scrivania/PROVA/LADD/src/federated/servers/oracle_server.py", line 35, in train_clients
    out = c.train(partial_metric, r=r)
  File "/home/utente/Scrivania/PROVA/LADD/src/clients/oracle_client.py", line 193, in train
    dict_all_iters_losses = self.run_epoch(epoch, optimizer, metric=partial_metric, r=r)
  File "/home/utente/Scrivania/PROVA/LADD/src/clients/oracle_client.py", line 165, in run_epoch
    self.__exec_epoch(optimizer, cur_epoch, metric, scheduler, plot_lr, dict_all_iters_losses,
  File "/home/utente/Scrivania/PROVA/LADD/src/clients/oracle_client.py", line 130, in __exec_epoch
    dict_calc_losses, outputs = self.calc_loss_and_output(images, labels)
  File "/home/utente/Scrivania/PROVA/LADD/src/clients/client.py", line 82, in calc_loss_and_output
    outputs = self.model(images)['out']
  File "/home/utente/anaconda3/envs/LADD/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/utente/anaconda3/envs/LADD/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 886, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/home/utente/anaconda3/envs/LADD/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/utente/anaconda3/envs/LADD/lib/python3.9/site-packages/torchvision/models/segmentation/_utils.py", line 25, in forward
    features = self.backbone(x)
  File "/home/utente/anaconda3/envs/LADD/lib/python3.9/site-packages/torch/fx/graph_module.py", line 616, in wrapped_call
    raise e.with_traceback(None)
RuntimeError: CUDA out of memory. Tried to allocate 768.00 MiB (GPU 0; 3.95 GiB total capacity; 2.15 GiB already allocated; 651.81 MiB free; 2.15 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF